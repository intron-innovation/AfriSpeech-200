{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e285aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81145b3f18d24110b08ac8647495eb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "\n",
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ab2ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/data/AfriSpeech-Dataset-Paper/'\n",
    "result_paths = [\n",
    "    'results/intron-open-test-wav2vec2-large-xlsr-53-generative_single_task_baseline-wer-0.2519-5474.csv',\n",
    "    'results/intron-open-test-wav2vec2-large-xlsr-53-generative-multitask-asr-domain-prepend-wer-0.2467-5474.csv',\n",
    "    'results/intron-open-test-atnafu-asr-domain-9-1-wer-0.2455-5474.csv'\n",
    "]\n",
    "data_paths = [\n",
    "    'data/intron-train-public-58000-clean.csv',\n",
    "    'data/intron-dev-public-3231-clean.csv',\n",
    "    'data/intron-test-public-6346-clean.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b986252",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(results_dir, data_paths[2]))\n",
    "train = pd.read_csv(os.path.join(results_dir, data_paths[0]))\n",
    "val = pd.read_csv(os.path.join(results_dir, data_paths[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1577ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "accent_counts = train.accent.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861888bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'yoruba': 14396,\n",
       " 'igbo': 8104,\n",
       " 'swahili': 5484,\n",
       " 'hausa': 5453,\n",
       " 'ijaw': 2371,\n",
       " 'afrikaans': 1911,\n",
       " 'idoma': 1767,\n",
       " 'twi': 1321,\n",
       " 'zulu': 1309,\n",
       " 'setswana': 1275,\n",
       " 'igala': 906,\n",
       " 'kiswahili': 811,\n",
       " 'izon': 783,\n",
       " 'isizulu': 779,\n",
       " 'ebira': 696,\n",
       " 'urhobo': 578,\n",
       " 'nembe': 546,\n",
       " 'luganda': 529,\n",
       " 'ibibio': 482,\n",
       " 'pidgin': 442,\n",
       " 'kinyarwanda': 439,\n",
       " 'luhya': 426,\n",
       " 'esan': 353,\n",
       " 'xhosa': 342,\n",
       " 'tshivenda': 334,\n",
       " 'alago': 310,\n",
       " 'tswana': 289,\n",
       " 'isoko': 259,\n",
       " 'fulani': 256,\n",
       " 'efik': 232,\n",
       " 'akan (fante)': 230,\n",
       " 'edo': 201,\n",
       " 'ikwere': 200,\n",
       " 'hausa/fulani': 192,\n",
       " 'isindebele': 188,\n",
       " 'luo': 179,\n",
       " 'sepedi': 176,\n",
       " 'venda and xitsonga': 174,\n",
       " 'bekwarra': 165,\n",
       " 'kikuyu': 163,\n",
       " 'isixhosa': 160,\n",
       " 'epie': 147,\n",
       " 'luganda and kiswahili': 134,\n",
       " 'akan': 131,\n",
       " 'sotho': 129,\n",
       " 'afemai': 125,\n",
       " 'kagoma': 123,\n",
       " 'nasarawa eggon': 120,\n",
       " 'south african english': 114,\n",
       " 'borana': 112,\n",
       " 'swahili ,luganda ,arabic': 109,\n",
       " 'nupe': 106,\n",
       " 'bette': 103,\n",
       " 'benin': 103,\n",
       " 'venda': 98,\n",
       " 'damara': 92,\n",
       " 'okrika': 90,\n",
       " 'southern sotho': 89,\n",
       " 'ogoni': 85,\n",
       " 'sesotho': 85,\n",
       " 'ngas': 82,\n",
       " 'etsako': 76,\n",
       " 'tiv': 75,\n",
       " 'shona': 73,\n",
       " 'luo, swahili': 71,\n",
       " 'dholuo': 70,\n",
       " 'ateso': 63,\n",
       " 'chichewa': 60,\n",
       " 'portuguese': 50,\n",
       " 'meru': 48,\n",
       " 'siswati': 26}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accent_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d3a038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_threshold = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a042aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_accents = [accent for accent, count in accent_counts.items() if count >= majority_threshold]\n",
    "minority_accents = [accent for accent, count in accent_counts.items() if count < majority_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad085a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accents = list(train.accent.unique()) + list(val.accent.unique())\n",
    "test_accents = list(test.accent.unique())\n",
    "ood_accents = [accent for accent in test_accents if accent not in train_accents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d42804e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "108\n",
      "18\n",
      "53\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(set(train_accents)))\n",
    "print(len(test_accents))\n",
    "print(len(majority_accents))\n",
    "print(len(minority_accents))\n",
    "print(len(ood_accents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f95942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6346, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a5726c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx', 'user_ids', 'accent', 'age_group', 'country', 'transcript',\n",
       "       'nchars', 'audio_ids', 'audio_paths', 'duration', 'origin', 'domain',\n",
       "       'split', 'gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa05855",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\n",
    "    'clinical', 'general', 'ood', 'majority', 'minority'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for result in results:\n",
    "# merge with metadata on audio paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b379e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " results/intron-open-test-wav2vec2-large-xlsr-53-generative_single_task_baseline-wer-0.2519-5474.csv\n",
      "clinical_wer:  0.2669\n",
      "general_wer:  0.2324\n",
      "ood_wer:  0.2605\n",
      "majority_wer:  0.2392\n",
      "minority_wer:  0.242\n",
      "\n",
      "\n",
      " results/intron-open-test-wav2vec2-large-xlsr-53-generative-multitask-asr-domain-prepend-wer-0.2467-5474.csv\n",
      "clinical_wer:  0.264\n",
      "general_wer:  0.225\n",
      "ood_wer:  0.2539\n",
      "majority_wer:  0.2331\n",
      "minority_wer:  0.2397\n",
      "\n",
      "\n",
      " results/intron-open-test-atnafu-asr-domain-9-1-wer-0.2455-5474.csv\n",
      "clinical_wer:  0.2598\n",
      "general_wer:  0.2267\n",
      "ood_wer:  0.255\n",
      "majority_wer:  0.2291\n",
      "minority_wer:  0.2395\n"
     ]
    }
   ],
   "source": [
    "for result_path in result_paths:\n",
    "    print('\\n\\n', result_path)\n",
    "    res = pd.read_csv(os.path.join(results_dir, result_path))\n",
    "    #print(res.sample(5))\n",
    "    res.drop_duplicates(subset=['audio_paths'], inplace=True)\n",
    "    res['audio_paths'] = res.apply(lambda row: row.audio_paths.replace('/data/data/intron/', '/AfriSpeech-100/test/'), axis=1)\n",
    "    # \n",
    "    res['audio_paths'] = res.apply(lambda row: row.audio_paths.replace('/media/4T/atnafu/adata/test/', '/AfriSpeech-100/test/'), axis=1)\n",
    "    \n",
    "    test.drop_duplicates(subset=['audio_paths'], inplace=True)\n",
    "    #print(test.sample(5))\n",
    "    pred = test.merge(res[['audio_paths', 'ref_clean', 'pred_clean']], how='left')[['audio_paths', 'ref_clean', 'pred_clean', 'accent', 'domain']]\n",
    "    #print(pred.shape)\n",
    "    #print(pred.sample(5))\n",
    "    \n",
    "    # clinical\n",
    "    clin = pred[pred.domain == 'clinical']\n",
    "    wer = wer_metric.compute(\n",
    "            predictions=clin[\"pred_clean\"].tolist(), references=clin[\"ref_clean\"].tolist()\n",
    "        )\n",
    "    print(\"clinical_wer: \", round(wer,4))\n",
    "    \n",
    "    # general\n",
    "    gen = pred[pred.domain == 'general']\n",
    "    wer = wer_metric.compute(\n",
    "            predictions=gen[\"pred_clean\"].tolist(), references=gen[\"ref_clean\"].tolist()\n",
    "        )\n",
    "    print(\"general_wer: \", round(wer,4))\n",
    "    \n",
    "    # ood\n",
    "    ood = pred[pred.accent.isin(ood_accents)]\n",
    "    wer = wer_metric.compute(\n",
    "            predictions=ood[\"pred_clean\"].tolist(), references=ood[\"ref_clean\"].tolist()\n",
    "        )\n",
    "    print(\"ood_wer: \", round(wer,4))\n",
    "    \n",
    "    # majority\n",
    "    major = pred[pred.accent.isin(majority_accents)]\n",
    "    wer = wer_metric.compute(\n",
    "            predictions=major[\"pred_clean\"].tolist(), references=major[\"ref_clean\"].tolist()\n",
    "        )\n",
    "    print(\"majority_wer: \", round(wer,4))\n",
    "    \n",
    "    # minority\n",
    "    minor = pred[pred.accent.isin(minority_accents)]\n",
    "    wer = wer_metric.compute(\n",
    "            predictions=minor[\"pred_clean\"].tolist(), references=minor[\"ref_clean\"].tolist()\n",
    "        )\n",
    "    print(\"minority_wer: \", round(wer,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7dff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.drop_duplicates(subset=['audio_paths'], inplace=True)\n",
    "ner.drop_duplicates(subset=['audio_paths'], inplace=True)\n",
    "merge_cols.append('audio_paths')\n",
    "\n",
    "ner_cols = ['audio_ids', 'audio_paths', 'has_entity', 'PER']\n",
    "predm = ner[ner_cols].merge(pred[merge_cols], how='left')\n",
    "#print(predm.shape)\n",
    "predm.drop_duplicates(subset=['audio_ids'], inplace=True)\n",
    "predm.drop_duplicates(subset=['audio_paths'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define groups/filters\n",
    "# loop through group \n",
    "# loop through results\n",
    "# and compute wer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_aws_neuron_pytorch_p36)",
   "language": "python",
   "name": "conda_aws_neuron_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
