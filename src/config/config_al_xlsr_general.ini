[experiment]
name = wav2vec2-large-xlsr-53-al-general
dir = /data/AfriSpeech-Dataset-Paper/src/experiments/wav2vec2-large-xlsr-53-al-general

[data]
train = /data/AfriSpeech-Dataset-Paper/data/intron-al-train-public-40600.csv
val = /data/AfriSpeech-Dataset-Paper/data/intron-al-dev-public-3232.csv
domain = general
aug = /data/AfriSpeech-Dataset-Paper/data/intron-al-aug-public-17401.csv
aug_percent = 0.5

[models]
model_path = facebook/wav2vec2-large-xlsr-53


[audio]
audio_path = /data/data/intron/

[checkpoints]
checkpoints_path = /data/AfriSpeech-Dataset-Paper/src/experiments/wav2vec2-large-xlsr-53-al-general/checkpoints/

[hyperparameters]
attention_dropout=0.1
hidden_dropout=0.1
feat_proj_dropout=0.0
mask_time_prob=0.05
layerdrop=0.1
gradient_checkpointing=True
gradient_accumulation_steps=1
ctc_loss_reduction=mean
freeze_feature_encoder=True
train_batch_size= 16
val_batch_size = 8
aug_batch_size = 1
save_steps=584
eval_steps = 584
learning_rate=3e-4
save_total_limit=3
dataloader_num_workers=5
seed=1778
group_by_length=False
load_best_model_at_end=True
ignore_data_skip=True
length_column_name=duration
data_seed=12260
ctc_zero_infinity=True
overwrite_output_dir=True
ddp_find_unused_parameters=False
max_audio_len=260000
max_label_len=260
max_audio_len_secs=17
min_transcript_len=10
top_k=10
active_learning_rounds=5
sampling_mode=most
mc_dropout_round = 10
num_epochs=1
warmup_steps=3
logging_steps=5

[logs]
train_logs = /data/AfriSpeech-Dataset-Paper/src/experiments/wav2vec2-large-xlsr-53-al-general/logs
figure_path = /data/AfriSpeech-Dataset-Paper/src/experiments/wav2vec2-large-xlsr-53-al-general/figures/
predictions_path = /data/AfriSpeech-Dataset-Paper/src/experiments/wav2vec2-large-xlsr-53-al-general/predictions/
