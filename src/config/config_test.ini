[experiment]
name = wav2vec2-large-xlsr-53
dir = /data/AfriSpeech-Dataset-Paper/src/experiments/wav2vec2-large-xlsr-53

[data]
train = /data/AfriSpeech-Dataset-Paper/data/intron-al-train-public-40600.csv
val = /data/AfriSpeech-Dataset-Paper/data/intron-al-dev-public-3232.csv
aug = /data/AfriSpeech-Dataset-Paper/data/intron-al-aug-public-17401.csv


[models]
model_path = facebook/wav2vec2-large-xlsr-53


[audio]
audio_path = /data/data/intron/
max_audio_len_secs = 17

[checkpoints]
checkpoints_path = /data/AfriSpeech-Dataset-Paper/src/experiments/wav2vec2-large-xlsr-53/checkpoints/

[hyperparameters]
attention_dropout = 0.1
hidden_dropout = 0.1
feat_proj_dropout = 0.0
mask_time_prob = 0.05
layerdrop = 0.1
gradient_checkpointing = True
gradient_accumulation_steps = 2
ctc_loss_reduction = mean
freeze_feature_encoder = True
train_batch_size = 16
val_batch_size = 8
num_epochs = 1
save_steps = 604
eval_steps = 604
logging_steps = 50
learning_rate = 3e-4
warmup_steps = 302
save_total_limit = 1
dataloader_num_workers = 5
max_audio_len = 260000
max_label_len = 260
seed = 1778
group_by_length = False
load_best_model_at_end = True
ignore_data_skip = True
length_column_name = duration
data_seed = 12260
ctc_zero_infinity = True
overwrite_output_dir = True
ddp_find_unused_parameters = False


[logs]
train_logs = /data/AfriSpeech-Dataset-Paper/src/experiments/wav2vec2-large-xlsr-53/logs
figure_path = /data/AfriSpeech-Dataset-Paper/src/experiments/wav2vec2-large-xlsr-53/figures/
predictions_path = /data/AfriSpeech-Dataset-Paper/src/experiments/wav2vec2-large-xlsr-53/predictions/